{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tqdm import *\n",
    "import os\n",
    "import argparse\n",
    "from GenerateData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前启用 cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "CUDA_ORDER=0\n",
    "DEVICE = torch.device(f\"cuda:{CUDA_ORDER}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前启用 {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/young/anaconda3/envs/pytorch/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Parser\n",
    "parser = argparse.ArgumentParser(description='DFVM')\n",
    "parser.add_argument('--dimension', type=int, default=100, metavar='N',\n",
    "                    help='dimension of the problem (default: 100)')\n",
    "parser.add_argument('--seed', type=int, default=0, metavar='N',\n",
    "                    help='random seed (default: 0)')\n",
    "seed = parser.parse_args().seed\n",
    "# Omega space domain\n",
    "DIMENSION = parser.parse_args().dimension\n",
    "a = [0 for _ in range(DIMENSION)]\n",
    "b = [1 for _ in range(DIMENSION)]\n",
    "\n",
    "# Finite Volume\n",
    "EPSILON = 1e-3         # Domain size\n",
    "BDSIZE = 1\n",
    "\n",
    "# Network\n",
    "DIM_INPUT = DIMENSION   # Input dimension\n",
    "NUM_UNIT = 40           # Number of neurons in a single layer\n",
    "DIM_OUTPUT = 1          # Output dimension\n",
    "NUM_LAYERS = 6          # Number of layers in the model\n",
    "\n",
    "# Optimizer\n",
    "IS_DECAY = 0\n",
    "LEARN_RATE = 1.1e-3      # Learning rate\n",
    "LEARN_FREQUENCY = 50     # Learning rate change interval\n",
    "LEARN_LOWWER_BOUND = 1e-5\n",
    "LEARN_DECAY_RATE = 0.99\n",
    "LOSS_FN = nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "CUDA_ORDER = \"0\"\n",
    "NUM_TRAIN_SMAPLE = 10000  # Size of the training set\n",
    "NUM_TRAIN_TIMES = 1       # Number of training samples\n",
    "NUM_ITERATION = 20000     # Number of training iterations per sample\n",
    "\n",
    "# Re-sampling\n",
    "IS_RESAMPLE = 0\n",
    "SAMPLE_FREQUENCY = 2000   # Re-sampling interval\n",
    "\n",
    "# Testing\n",
    "NUM_TEST_SAMPLE = 10000\n",
    "TEST_FREQUENCY = 1        # Output interval\n",
    "\n",
    "# Loss weight\n",
    "BETA = 1000               # Weight of the boundary loss function\n",
    "\n",
    "# Save model\n",
    "IS_SAVE_MODEL = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline():\n",
    "    # define device\n",
    "    DEVICE = torch.device(f\"cuda:{CUDA_ORDER}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #DEVICE = torch.device(\"cpu\")\n",
    "    print(f\"当前启用 {DEVICE}\")\n",
    "    # define equation\n",
    "    Eq = PoissonEQuation(DIMENSION, EPSILON, BDSIZE, DEVICE)\n",
    "    # define model\n",
    "    # torch.set_default_dtype(torch.float64)\n",
    "    model = MLP(DIM_INPUT, DIM_OUTPUT, NUM_UNIT).to(DEVICE)\n",
    "    optA   = torch.optim.Adam(model.parameters(), lr=LEARN_RATE) \n",
    "    solver = DFVMsolver(Eq, model, DEVICE)\n",
    "\n",
    "    x      = Eq.interior(NUM_TRAIN_SMAPLE)\n",
    "    x_bd   = Eq.neighborhoodBD(x)\n",
    "    print(x_bd.shape)\n",
    "    int_f  = solver.integrate_F(x)\n",
    "    bd_dir = Eq.outerNormalVec()\n",
    "    x_boundary = Eq.boundary(100)\n",
    "    \n",
    "    # 网络迭代\n",
    "    elapsed_time     = 0    # 计时\n",
    "    training_history = []    # 记录数据\n",
    "\n",
    "    for step in tqdm(range(NUM_ITERATION+1)):\n",
    "        if IS_DECAY and step and step % LEARN_FREQUENCY == 0:\n",
    "            for p in optA.param_groups:\n",
    "                if p['lr'] > LEARN_LOWWER_BOUND:\n",
    "                    p['lr'] = p['lr']*LEARN_DECAY_RATE\n",
    "                    print(f\"Learning Rate: {p['lr']}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        int_bd   = solver.integrate_BD(x, x_bd, bd_dir).reshape(-1,1)\n",
    "        loss_int = LOSS_FN(-int_bd, int_f)\n",
    "        loss_bd  = solver.loss_boundary(x_boundary)\n",
    "        loss     = loss_int + BETA*loss_bd \n",
    "        optA.zero_grad()\n",
    "        loss.backward()\n",
    "        optA.step()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        elapsed_time = elapsed_time + epoch_time\n",
    "        if step % TEST_FREQUENCY == 0:\n",
    "            loss_int     = loss_int.cpu().detach().numpy()\n",
    "            loss_bd      = loss_bd.cpu().detach().numpy()\n",
    "            loss         = loss.cpu().detach().numpy()\n",
    "            L2error,ME,T = solver.TEST(NUM_TEST_SAMPLE)\n",
    "            if step and step%1000 == 0:\n",
    "                tqdm.write( f'\\nStep: {step:>5}, '\n",
    "                            f'Loss_int: {loss_int:>10.5f}, '\n",
    "                            f'Loss_bd: {loss_bd:>10.5f}, '\n",
    "                            f'Loss: {loss:>10.5f}, '                                     \n",
    "                            f'L2 error: {L2error:.5f}, '                                     \n",
    "                            f'Time: {elapsed_time:.2f}')\n",
    "            training_history.append([step, L2error, ME, loss, elapsed_time, epoch_time, T])\n",
    "\n",
    "    training_history = np.array(training_history)\n",
    "    print(np.min(training_history[:,1]))\n",
    "    print(np.min(training_history[:,2]))\n",
    "\n",
    "    save_time = time.localtime()\n",
    "    save_time = f'[{save_time.tm_mday:0>2d}{save_time.tm_hour:0>2d}{save_time.tm_min:0>2d}]'\n",
    "    dir_path  = os.getcwd() + f'/PossionEQ_seed{seed}/'\n",
    "    file_name = f'{DIMENSION}DIM-DFVM-{BETA}weight-{NUM_ITERATION}itr-{EPSILON}R-{BDSIZE}bd-{LEARN_RATE}lr.csv'\n",
    "    file_path = dir_path + file_name\n",
    "\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    np.savetxt(file_path, training_history,\n",
    "                delimiter =\",\",\n",
    "                header    =\"step, L2error, MaxError, loss, elapsed_time, epoch_time, inference_time\",\n",
    "                comments  ='')\n",
    "    print('Training History Saved!')\n",
    "\n",
    "    if IS_SAVE_MODEL:\n",
    "        torch.save(model.state_dict(), dir_path + f'{DIMENSION}DIM-DFVM_net')\n",
    "        print('DFVM Network Saved!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_seed(seed)\n",
    "    train_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
